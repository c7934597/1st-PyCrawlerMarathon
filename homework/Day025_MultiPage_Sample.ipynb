{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 教學目標\n",
    "\n",
    "- 複習 PTT 文章的爬蟲邏輯\n",
    "- 熟悉單網站多網頁，透過列表將連結內的文章內容都爬下來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# PTT 八卦版網址\n",
    "PTT_URL = 'https://www.ptt.cc/bbs/Gossiping/index.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例重點\n",
    "\n",
    "這個練習題在 PTT 單頁文章上的程式碼比較多，建議可以先把他寫成一個 function 方便後面程式邏輯的撰寫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_article(url):\n",
    "    response = requests.get(url, cookies={'over18': '1'})\n",
    "    \n",
    "    # 假設網頁回應不是 200 OK 的話, 我們視為傳送請求失敗\n",
    "    if response.status_code != 200:\n",
    "        print('Error - {} is not available to access'.format(url))\n",
    "        return\n",
    "    \n",
    "    # 將網頁回應的 HTML 傳入 BeautifulSoup 解析器, 方便我們根據標籤 (tag) 資訊去過濾尋找\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    \n",
    "    # 取得文章內容主體\n",
    "    main_content = soup.find(id='main-content')\n",
    "    \n",
    "    # 假如文章有屬性資料 (meta), 我們在從屬性的區塊中爬出作者 (author), 文章標題 (title), 發文日期 (date)\n",
    "    metas = main_content.select('div.article-metaline') #list\n",
    "    author = ''\n",
    "    title = ''\n",
    "    date = ''\n",
    "    if metas:\n",
    "        if metas[0].select('span.article-meta-value')[0]:\n",
    "            author = metas[0].select('span.article-meta-value')[0].string\n",
    "        if metas[1].select('span.article-meta-value')[0]:\n",
    "            title = metas[1].select('span.article-meta-value')[0].string\n",
    "        if metas[2].select('span.article-meta-value')[0]:\n",
    "            date = metas[2].select('span.article-meta-value')[0].string\n",
    "\n",
    "        # 從 main_content 中移除 meta 資訊（author, title, date 與其他看板資訊）\n",
    "        #\n",
    "        # .extract() 方法可以參考官方文件\n",
    "        #  - https://www.crummy.com/software/BeautifulSoup/bs4/doc/#extract\n",
    "        for m in metas:\n",
    "            m.extract()\n",
    "        for m in main_content.select('div.article-metaline-right'):\n",
    "            m.extract()\n",
    "    \n",
    "    # 取得留言區主體\n",
    "    pushes = main_content.find_all('div', class_='push')\n",
    "    for p in pushes:\n",
    "        p.extract()\n",
    "    \n",
    "    # 假如文章中有包含「※ 發信站: 批踢踢實業坊(ptt.cc), 來自: xxx.xxx.xxx.xxx」的樣式\n",
    "    # 透過 regular expression 取得 IP\n",
    "    # 因為字串中包含特殊符號跟中文, 這邊建議使用 unicode 的型式 u'...'\n",
    "    try:\n",
    "        ip = main_content.find(text=re.compile(u'※ 發信站:'))\n",
    "        ip = re.search('[0-9]*\\.[0-9]*\\.[0-9]*\\.[0-9]*', ip).group()\n",
    "    except Exception as e:\n",
    "        ip = ''\n",
    "    \n",
    "    # 移除文章主體中 '※ 發信站:', '◆ From:', 空行及多餘空白 (※ = u'\\u203b', ◆ = u'\\u25c6')\n",
    "    # 保留英數字, 中文及中文標點, 網址, 部分特殊符號\n",
    "    #\n",
    "    # 透過 .stripped_strings 的方式可以快速移除多餘空白並取出文字, 可參考官方文件 \n",
    "    #  - https://www.crummy.com/software/BeautifulSoup/bs4/doc/#strings-and-stripped-strings\n",
    "    filtered = []\n",
    "    for v in main_content.stripped_strings:\n",
    "        # 假如字串開頭不是特殊符號或是以 '--' 開頭的, 我們都保留其文字\n",
    "        if v[0] not in [u'※', u'◆'] and v[:2] not in [u'--']:\n",
    "            filtered.append(v)\n",
    "\n",
    "    # 定義一些特殊符號與全形符號的過濾器\n",
    "    expr = re.compile(u'[^一-龥。；，：“”（）、？《》\\s\\w:/-_.?~%()]')\n",
    "    for i in range(len(filtered)):\n",
    "        filtered[i] = re.sub(expr, '', filtered[i])\n",
    "    \n",
    "    # 移除空白字串, 組合過濾後的文字即為文章本文 (content)\n",
    "    filtered = [i for i in filtered if i]\n",
    "    content = ' '.join(filtered)\n",
    "    \n",
    "    # 處理留言區\n",
    "    # p 計算推文數量\n",
    "    # b 計算噓文數量\n",
    "    # n 計算箭頭數量\n",
    "    p, b, n = 0, 0, 0\n",
    "    messages = []\n",
    "    for push in pushes:\n",
    "        # 假如留言段落沒有 push-tag 就跳過\n",
    "        if not push.find('span', 'push-tag'):\n",
    "            continue\n",
    "        \n",
    "        # 過濾額外空白與換行符號\n",
    "        # push_tag 判斷是推文, 箭頭還是噓文\n",
    "        # push_userid 判斷留言的人是誰\n",
    "        # push_content 判斷留言內容\n",
    "        # push_ipdatetime 判斷留言日期時間\n",
    "        push_tag = push.find('span', 'push-tag').string.strip(' \\t\\n\\r')\n",
    "        push_userid = push.find('span', 'push-userid').string.strip(' \\t\\n\\r')\n",
    "        push_content = push.find('span', 'push-content').strings\n",
    "        push_content = ' '.join(push_content)[1:].strip(' \\t\\n\\r')\n",
    "        push_ipdatetime = push.find('span', 'push-ipdatetime').string.strip(' \\t\\n\\r')\n",
    "\n",
    "        # 整理打包留言的資訊, 並統計推噓文數量\n",
    "        messages.append({\n",
    "            'push_tag': push_tag,\n",
    "            'push_userid': push_userid,\n",
    "            'push_content': push_content,\n",
    "            'push_ipdatetime': push_ipdatetime})\n",
    "        if push_tag == u'推':\n",
    "            p += 1\n",
    "        elif push_tag == u'噓':\n",
    "            b += 1\n",
    "        else:\n",
    "            n += 1\n",
    "    \n",
    "    # 統計推噓文\n",
    "    # count 為推噓文相抵看這篇文章推文還是噓文比較多\n",
    "    # all 為總共留言數量 \n",
    "    message_count = {'all': p+b+n, 'count': p-b, 'push': p, 'boo': b, 'neutral': n}\n",
    "    \n",
    "    # 整理文章資訊\n",
    "    data = {\n",
    "        'url': url,\n",
    "        'article_author': author,\n",
    "        'article_title': title,\n",
    "        'article_date': date,\n",
    "        'article_content': content,\n",
    "        'ip': ip,\n",
    "        'message_count': message_count,\n",
    "        'messages': messages\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例重點\n",
    "\n",
    "分析列表取得要爬蟲的網址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Re: [問卦] 幹 伯朗咖啡的口味太多了吧== - https://www.ptt.cc/bbs/Gossiping/M.1577519273.A.9B9.html\n",
      "Parse [問卦] Minecraft產業鏈到底有多大???? - https://www.ptt.cc/bbs/Gossiping/M.1577519337.A.03F.html\n",
      "Parse Re: [新聞] 鄭宏輝遭轟用「中國台灣」名義經商！　「 - https://www.ptt.cc/bbs/Gossiping/M.1577519346.A.569.html\n",
      "Parse [問卦] 有沒有義消的八卦？ - https://www.ptt.cc/bbs/Gossiping/M.1577519384.A.25B.html\n",
      "Parse [新聞] 夏威夷觀光直升機墜毀 尋獲6遺體、1人下落不明 - https://www.ptt.cc/bbs/Gossiping/M.1577519602.A.DDE.html\n",
      "Parse Re: [爆卦] 館長要辦遊行啦 - https://www.ptt.cc/bbs/Gossiping/M.1577519711.A.A68.html\n",
      "Parse [問卦] 求發財! 飛行夾克有啥大廠代工? - https://www.ptt.cc/bbs/Gossiping/M.1577519868.A.F27.html\n",
      "Parse [問卦] 風雲起 山河動 預備 唱 - https://www.ptt.cc/bbs/Gossiping/M.1577520100.A.7A1.html\n",
      "Parse Re: [問卦] 勞退提撥根本智障！ - https://www.ptt.cc/bbs/Gossiping/M.1577520115.A.02D.html\n",
      "Parse [問卦] 跟朋友一起看片都去哪？ - https://www.ptt.cc/bbs/Gossiping/M.1577520315.A.9A4.html\n",
      "Parse [問卦] 綁過小妹大腿的健身環可以賣多少？ - https://www.ptt.cc/bbs/Gossiping/M.1577520319.A.73E.html\n",
      "Parse [問卦] 女醫森是不是都很棒？ - https://www.ptt.cc/bbs/Gossiping/M.1577520331.A.C0F.html\n",
      "Reach the last article\n"
     ]
    }
   ],
   "source": [
    "# 對文章列表送出請求並取得列表主體\n",
    "resp = requests.get(PTT_URL, cookies={'over18': '1'})\n",
    "soup = BeautifulSoup(resp.text)\n",
    "main_list = soup.find('div', class_='bbs-screen')\n",
    "all_data = []\n",
    "\n",
    "# 依序檢查文章列表中的 tag, 遇到分隔線就結束, 忽略這之後的文章\n",
    "for div in main_list.findChildren('div', recursive=False):\n",
    "    class_name = div.attrs['class']  #['search-bar']['r-ent']['r-ent']...\n",
    "    \n",
    "    # 遇到分隔線要處理的情況\n",
    "    if class_name and 'r-list-sep' in class_name:\n",
    "        print('Reach the last article')\n",
    "        break\n",
    "    \n",
    "    # 遇到目標文章\n",
    "    if class_name and 'r-ent' in class_name:\n",
    "        div_title = div.find('div', class_='title')\n",
    "        a_title = div_title.find('a', href=True)\n",
    "        if a_title:\n",
    "            article_URL = urljoin(PTT_URL, a_title['href'])\n",
    "        else:\n",
    "            article_URL = None\n",
    "            a_title = '<a>本文已刪除</a>'\n",
    "        article_title = a_title.text\n",
    "        print('Parse {} - {}'.format(article_title, article_URL))\n",
    "        \n",
    "        # 呼叫上面寫好的 function 來對文章進行爬蟲\n",
    "        if article_URL:\n",
    "            parse_data = crawl_article(article_URL) # 返回單一文章資訊的字典\n",
    "        \n",
    "        # 將爬完的資料儲存\n",
    "        all_data.append(parse_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將爬完的資訊存成 json 檔案\n",
    "with open('../Data/parse_data.json', 'w+', encoding='utf-8') as f:\n",
    "    json.dump(all_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下為理解過程:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"article-metaline\"><span class=\"article-meta-tag\">作者</span><span class=\"article-meta-value\">joe911joeop (喬)</span></div>,\n",
       " <div class=\"article-metaline\"><span class=\"article-meta-tag\">標題</span><span class=\"article-meta-value\">[問卦] 可能我的瘋狂  暫時不得到原諒？</span></div>,\n",
       " <div class=\"article-metaline\"><span class=\"article-meta-tag\">時間</span><span class=\"article-meta-value\">Sat Dec 28 10:57:38 2019</span></div>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html', cookies={'over18': '1'})\n",
    "    \n",
    "# 假設網頁回應不是 200 OK 的話, 我們視為傳送請求失敗\n",
    "if response.status_code != 200:\n",
    "    print('Error - {} is not available to access'.format(url))\n",
    "\n",
    "# 將網頁回應的 HTML 傳入 BeautifulSoup 解析器, 方便我們根據標籤 (tag) 資訊去過濾尋找\n",
    "soup = BeautifulSoup(response.text)\n",
    "\n",
    "# 取得文章內容主體\n",
    "main_content = soup.find(id='main-content')\n",
    "\n",
    "# 假如文章有屬性資料 (meta), 我們在從屬性的區塊中爬出作者 (author), 文章標題 (title), 發文日期 (date)\n",
    "metas = main_content.select('div.article-metaline') #list\n",
    "author = ''\n",
    "title = ''\n",
    "date = ''\n",
    "metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"bbs-screen bbs-content\" id=\"main-content\"><div class=\"article-metaline\"><span class=\"article-meta-tag\">作者</span><span class=\"article-meta-value\">joe911joeop (喬)</span></div><div class=\"article-metaline-right\"><span class=\"article-meta-tag\">看板</span><span class=\"article-meta-value\">Gossiping</span></div><div class=\"article-metaline\"><span class=\"article-meta-tag\">標題</span><span class=\"article-meta-value\">[問卦] 可能我的瘋狂  暫時不得到原諒？</span></div><div class=\"article-metaline\"><span class=\"article-meta-tag\">時間</span><span class=\"article-meta-value\">Sat Dec 28 10:57:38 2019</span></div>\n",
      "可是我知道啊  可是我明白啊\n",
      "\n",
      "是我的執著搏來  在你面前歌唱\n",
      "\n",
      "\n",
      "吶，有沒有十年一刻的八卦呀？\n",
      "\n",
      "--\n",
      "<span class=\"f2\">※ 發信站: 批踢踢實業坊(ptt.cc), 來自: 223.136.193.168 (臺灣)\n",
      "</span><span class=\"f2\">※ 文章網址: <a href=\"https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html\" rel=\"nofollow\" target=\"_blank\">https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html</a>\n",
      "</span><div class=\"push\"><span class=\"hl push-tag\">推 </span><span class=\"f3 hl push-userid\">johnny</span><span class=\"f3 push-content\">: 總統票投二號 政黨票支持民眾黨</span><span class=\"push-ipdatetime\">   223.138.90.6 12/28 10:58\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">→ </span><span class=\"f3 hl push-userid\">https</span><span class=\"f3 push-content\">: 是不是跟老闆翻臉才休團的阿?</span><span class=\"push-ipdatetime\">203.163.204.204 12/28 10:59\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">→ </span><span class=\"f3 hl push-userid\">kuo1102</span><span class=\"f3 push-content\">:    五樓喜歡你的瘋狂在屁眼狂射</span><span class=\"push-ipdatetime\">  131.129.74.13 12/28 10:59\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">噓 </span><span class=\"f3 hl push-userid\">deepdish</span><span class=\"f3 push-content\">: 太早</span><span class=\"push-ipdatetime\"> 220.134.89.190 12/28 11:00\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">噓 </span><span class=\"f3 hl push-userid\">aa85720tw</span><span class=\"f3 push-content\">: 現在大家都在聽寂寞的時候 我好想念前</span><span class=\"push-ipdatetime\">  111.71.32.211 12/28 11:17\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">→ </span><span class=\"f3 hl push-userid\">aa85720tw</span><span class=\"f3 push-content\">: 輩QQ</span><span class=\"push-ipdatetime\">  111.71.32.211 12/28 11:17\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">→ </span><span class=\"f3 hl push-userid\">akumo</span><span class=\"f3 push-content\">: 大旱</span><span class=\"push-ipdatetime\"> 36.235.247.240 12/28 11:23\n",
      "</span></div></div>\n",
      "---------------------------\n",
      "<div class=\"bbs-screen bbs-content\" id=\"main-content\">\n",
      "可是我知道啊  可是我明白啊\n",
      "\n",
      "是我的執著搏來  在你面前歌唱\n",
      "\n",
      "\n",
      "吶，有沒有十年一刻的八卦呀？\n",
      "\n",
      "--\n",
      "<span class=\"f2\">※ 發信站: 批踢踢實業坊(ptt.cc), 來自: 223.136.193.168 (臺灣)\n",
      "</span><span class=\"f2\">※ 文章網址: <a href=\"https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html\" rel=\"nofollow\" target=\"_blank\">https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html</a>\n",
      "</span><div class=\"push\"><span class=\"hl push-tag\">推 </span><span class=\"f3 hl push-userid\">johnny</span><span class=\"f3 push-content\">: 總統票投二號 政黨票支持民眾黨</span><span class=\"push-ipdatetime\">   223.138.90.6 12/28 10:58\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">→ </span><span class=\"f3 hl push-userid\">https</span><span class=\"f3 push-content\">: 是不是跟老闆翻臉才休團的阿?</span><span class=\"push-ipdatetime\">203.163.204.204 12/28 10:59\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">→ </span><span class=\"f3 hl push-userid\">kuo1102</span><span class=\"f3 push-content\">:    五樓喜歡你的瘋狂在屁眼狂射</span><span class=\"push-ipdatetime\">  131.129.74.13 12/28 10:59\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">噓 </span><span class=\"f3 hl push-userid\">deepdish</span><span class=\"f3 push-content\">: 太早</span><span class=\"push-ipdatetime\"> 220.134.89.190 12/28 11:00\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">噓 </span><span class=\"f3 hl push-userid\">aa85720tw</span><span class=\"f3 push-content\">: 現在大家都在聽寂寞的時候 我好想念前</span><span class=\"push-ipdatetime\">  111.71.32.211 12/28 11:17\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">→ </span><span class=\"f3 hl push-userid\">aa85720tw</span><span class=\"f3 push-content\">: 輩QQ</span><span class=\"push-ipdatetime\">  111.71.32.211 12/28 11:17\n",
      "</span></div><div class=\"push\"><span class=\"f1 hl push-tag\">→ </span><span class=\"f3 hl push-userid\">akumo</span><span class=\"f3 push-content\">: 大旱</span><span class=\"push-ipdatetime\"> 36.235.247.240 12/28 11:23\n",
      "</span></div></div>\n"
     ]
    }
   ],
   "source": [
    "print(main_content)\n",
    "print('---------------------------')\n",
    "if metas:\n",
    "    if metas[0].select('span.article-meta-value')[0]:\n",
    "        author = metas[0].select('span.article-meta-value')[0].string\n",
    "    if metas[1].select('span.article-meta-value')[0]:\n",
    "        title = metas[1].select('span.article-meta-value')[0].string\n",
    "    if metas[2].select('span.article-meta-value')[0]:\n",
    "        date = metas[2].select('span.article-meta-value')[0].string\n",
    "\n",
    "    # 從 main_content 中移除 meta 資訊（author, title, date 與其他看板資訊）\n",
    "    #\n",
    "    # .extract() 方法可以參考官方文件\n",
    "    #  - https://www.crummy.com/software/BeautifulSoup/bs4/doc/#extract\n",
    "    for m in metas:\n",
    "        m.extract()\n",
    "    for m in main_content.select('div.article-metaline-right'):\n",
    "        m.extract()\n",
    "print(main_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"bbs-screen bbs-content\" id=\"main-content\">\n",
      "可是我知道啊  可是我明白啊\n",
      "\n",
      "是我的執著搏來  在你面前歌唱\n",
      "\n",
      "\n",
      "吶，有沒有十年一刻的八卦呀？\n",
      "\n",
      "--\n",
      "<span class=\"f2\">※ 發信站: 批踢踢實業坊(ptt.cc), 來自: 223.136.193.168 (臺灣)\n",
      "</span><span class=\"f2\">※ 文章網址: <a href=\"https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html\" rel=\"nofollow\" target=\"_blank\">https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html</a>\n",
      "</span></div>\n",
      "~~~~~~~~\n",
      "一 ※ 發信站: 批踢踢實業坊(ptt.cc), 來自: 223.136.193.168 (臺灣)\n",
      "\n",
      "二 223.136.193.168\n"
     ]
    }
   ],
   "source": [
    "# 取得留言區主體，然後也將推文拿掉\n",
    "pushes = main_content.find_all('div', class_='push')\n",
    "for p in pushes:\n",
    "    p.extract()\n",
    "print(main_content)\n",
    "print('~~~~~~~~')\n",
    "# 假如文章中有包含「※ 發信站: 批踢踢實業坊(ptt.cc), 來自: xxx.xxx.xxx.xxx」的樣式\n",
    "# 透過 regular expression 取得 IP\n",
    "# 因為字串中包含特殊符號跟中文, 這邊建議使用 unicode 的型式 u'...'\n",
    "try:\n",
    "    ip = main_content.find(text=re.compile(u'※ 發信站:'))\n",
    "    print('一',ip)\n",
    "    ip = re.search('[0-9]*\\.[0-9]*\\.[0-9]*\\.[0-9]*', ip).group()\n",
    "    print('二',ip)\n",
    "except Exception as e:\n",
    "    ip = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可是我知道啊  可是我明白啊\n",
      "\n",
      "是我的執著搏來  在你面前歌唱\n",
      "\n",
      "\n",
      "吶，有沒有十年一刻的八卦呀？\n",
      "\n",
      "--\n",
      "※ 發信站: 批踢踢實業坊(ptt.cc), 來自: 223.136.193.168 (臺灣)\n",
      "※ 文章網址:\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html\n",
      "~~~\n",
      "['可是我知道啊  可是我明白啊\\n\\n是我的執著搏來  在你面前歌唱\\n\\n\\n吶，有沒有十年一刻的八卦呀？\\n\\n--', 'https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html']\n"
     ]
    }
   ],
   "source": [
    "# 移除文章主體中 '※ 發信站:', '◆ From:', 空行及多餘空白 (※ = u'\\u203b', ◆ = u'\\u25c6')\n",
    "# 保留英數字, 中文及中文標點, 網址, 部分特殊符號\n",
    "#\n",
    "# 透過 .stripped_strings 的方式可以快速移除多餘空白並取出文字, 可參考官方文件 \n",
    "#  - https://www.crummy.com/software/BeautifulSoup/bs4/doc/#strings-and-stripped-strings\n",
    "filtered = []\n",
    "for v in main_content.stripped_strings:\n",
    "    print(v)\n",
    "    # 假如字串開頭不是特殊符號或是以 '--' 開頭的, 我們都保留其文字\n",
    "    if v[0] not in [u'※', u'◆'] and v[:2] not in [u'--']:\n",
    "        filtered.append(v)\n",
    "print('~~~')\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['可是我知道啊  可是我明白啊\\n\\n是我的執著搏來  在你面前歌唱\\n\\n\\n吶，有沒有十年一刻的八卦呀？\\n\\n', 'https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html']\n"
     ]
    }
   ],
   "source": [
    "# 定義一些特殊符號與全形符號的過濾器\n",
    "expr = re.compile(u'[^一-龥。；，：“”（）、？《》\\s\\w:/-_.?~%()]')\n",
    "for i in range(len(filtered)):\n",
    "    filtered[i] = re.sub(expr, '', filtered[i])\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['可是我知道啊  可是我明白啊\\n\\n是我的執著搏來  在你面前歌唱\\n\\n\\n吶，有沒有十年一刻的八卦呀？\\n\\n', 'https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html']\n"
     ]
    }
   ],
   "source": [
    "# 移除空白字串, 組合過濾後的文字即為文章本文 (content)\n",
    "filtered = [i for i in filtered if i]\n",
    "content = ' '.join(filtered)\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可是我知道啊  可是我明白啊\n",
      "\n",
      "是我的執著搏來  在你面前歌唱\n",
      "\n",
      "\n",
      "吶，有沒有十年一刻的八卦呀？\n",
      "\n",
      " https://www.ptt.cc/bbs/Gossiping/M.1577501860.A.D2F.html\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
